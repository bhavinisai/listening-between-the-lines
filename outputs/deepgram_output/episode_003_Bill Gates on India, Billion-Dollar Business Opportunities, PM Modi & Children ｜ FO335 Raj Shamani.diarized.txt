[00:00:00.080 - 00:00:01.540] Speaker 1: What's the biggest misunderstanding
[00:00:02.080 - 00:00:29.540] Speaker 2: about you? Whenever you hear about somebody who's got, you know, ridiculous amounts of money, their values are different than your values. You should be concerned about their agenda. What's your biggest fear? I'll be sad as my brain gets less capable. That disappoints me. Tell me one behavior we all should adopt. Reading a lot, being a student, that's a big part of my success. Richest and most powerful men in the world. Bill Gates has unleashed a technological revolution
[00:00:30.320 - 00:00:38.340] Speaker 1: that has changed our lives. Bill Gates are 25 and Bill Gates are 70. Any change that you feel personally? In my twenties, being a maniac
[00:00:38.720 - 00:00:50.115] Speaker 2: was the right thing. My competitors would say, oh, no. You work too hard. And I'd say, yes. I do. If you're in a race, your twenties when you have no wife and no children, that's the time to do it.
[00:00:52.175 - 00:00:58.140] Speaker 1: If you get an opportunity to invite three Indians for dinner, who would that be? There was a mathematician,
[00:00:58.920 - 00:00:59.420] Speaker 2: Ramanujan.
[00:00:59.880 - 00:01:03.340] Speaker 2: I would have loved to have met him. Why do you think India is becoming
[00:01:03.720 - 00:01:18.505] Speaker 2: a global talent capital for the world? Would hire people from India and bring them to The United States. You know, both The United States and India were kind of mad at us because we were taking, you know, the smart people and moving them. In India, a lot of kids also fight with their parents on inheritance.
[00:01:18.805 - 00:01:21.065] Speaker 1: Have your kids ever spoken to you?
[00:01:27.690 - 00:01:29.550] Speaker 1: Before we start today's episode,
[00:01:30.010 - 00:01:35.230] Speaker 1: all I want to say is thank you to each and every one of you. I'm really grateful
[00:01:35.850 - 00:01:36.350] Speaker 1: that
[00:01:37.005 - 00:01:40.625] Speaker 1: we were able to sit down with one of the most influential
[00:01:41.005 - 00:01:41.505] Speaker 1: men
[00:01:41.885 - 00:01:42.785] Speaker 1: in the world
[00:01:43.245 - 00:01:44.305] Speaker 1: the Bill Gates.
[00:01:45.485 - 00:01:53.650] Speaker 1: I have been this young boy who always used to hear stories about this man about the kind of money he has made, the kind of lives he's impacting,
[00:01:53.950 - 00:01:56.130] Speaker 1: the kind of things he's building through Microsoft.
[00:01:56.990 - 00:01:57.650] Speaker 1: From there
[00:01:58.430 - 00:02:01.330] Speaker 1: to be sitting in front of him, it was surreal.
[00:02:01.790 - 00:02:07.755] Speaker 1: When I started the conversation you could see it on my face that I was really nervous really scared. I didn't know what to talk about but
[00:02:08.135 - 00:02:09.995] Speaker 1: as we went in the conversation
[00:02:10.855 - 00:02:15.115] Speaker 1: the podcaster in me took over and we spoke about his fears,
[00:02:15.490 - 00:02:16.310] Speaker 1: his misunderstandings,
[00:02:17.170 - 00:02:23.270] Speaker 1: the mission, and what is he doing today. Today, I want you to see this episode from a lens of
[00:02:23.570 - 00:02:25.990] Speaker 1: a 20 year old sitting with
[00:02:26.370 - 00:02:27.110] Speaker 1: Bill Gates
[00:02:27.490 - 00:02:30.390] Speaker 1: and figuring out what goes on in his brain.
[00:02:30.945 - 00:02:32.805] Speaker 1: This episode is truly special
[00:02:33.265 - 00:02:33.765] Speaker 1: because
[00:02:34.305 - 00:02:36.725] Speaker 1: I could have never thought that
[00:02:37.185 - 00:02:39.445] Speaker 1: Bill Gates will be on our podcast
[00:02:39.825 - 00:02:43.525] Speaker 1: this soon in our journey. I always had a belief that
[00:02:43.985 - 00:02:47.480] Speaker 1: we will be able to sit down with the smartest people
[00:02:48.100 - 00:02:50.680] Speaker 1: around the world. Will it happen this soon?
[00:02:52.020 - 00:02:54.440] Speaker 1: I can't believe this right now.
[00:02:54.980 - 00:03:02.295] Speaker 1: I just want you to enjoy this episode the way I did. I want you to sink in that this is happening because it's not sinking in with
[00:03:02.675 - 00:03:04.935] Speaker 1: me. And I just wanna tell you that
[00:03:05.315 - 00:03:10.775] Speaker 1: there are more episodes coming, so keep supporting us and hit the subscribe button right now.
[00:03:15.650 - 00:03:20.310] Speaker 1: Welcome on Figuring Out, sir. I'll tell you a little story. So during the pandemic,
[00:03:20.930 - 00:03:23.990] Speaker 1: me and my sister, we were watching the Netflix documentary
[00:03:24.290 - 00:03:25.510] Speaker 1: inside Bill's brain
[00:03:25.970 - 00:03:26.470] Speaker 1: and
[00:03:26.770 - 00:03:29.195] Speaker 1: halfway through it, I told my sister
[00:03:29.735 - 00:03:33.195] Speaker 1: that, hey, you know what? Like, one day I'll sit with Bill Gates and
[00:03:34.055 - 00:03:39.435] Speaker 1: I'll directly speak to him and get inside his brain. And she's randomly and she was laughing.
[00:03:39.895 - 00:03:41.195] Speaker 1: So this one's for you.
[00:03:42.570 - 00:03:52.830] Speaker 1: You did it. Yeah. So it's it's an opportunity. I don't know how it just came out of my mouth and it's happening today. So thank you so much for doing this. Well,
[00:03:53.210 - 00:03:55.150] Speaker 1: you've come to India quite often.
[00:03:56.145 - 00:03:57.125] Speaker 1: Tell me something
[00:03:57.505 - 00:03:59.765] Speaker 1: that you've observed about India, which
[00:04:00.065 - 00:04:02.725] Speaker 1: a lot of people don't know about. Well, people probably,
[00:04:04.385 - 00:04:06.325] Speaker 2: you know, because they're here all the time.
[00:04:06.785 - 00:04:12.870] Speaker 2: You know, they probably don't recognize how much things have changed. And if you go away and come back, then you see, wow,
[00:04:13.170 - 00:04:13.830] Speaker 2: you know,
[00:04:14.370 - 00:04:15.750] Speaker 2: the level of entrepreneurship
[00:04:16.290 - 00:04:17.030] Speaker 2: and the,
[00:04:18.370 - 00:04:22.390] Speaker 2: you know, the amount of innovation that's actually taking place here,
[00:04:23.250 - 00:04:24.755] Speaker 2: it's pretty fantastic.
[00:04:25.615 - 00:04:26.115] Speaker 2: And,
[00:04:26.415 - 00:04:29.315] Speaker 2: you know, for the foundation, we've been here originally,
[00:04:30.575 - 00:04:33.635] Speaker 2: because a lot of the health challenges were here,
[00:04:34.015 - 00:04:36.595] Speaker 2: and we still care a lot about that. But,
[00:04:37.135 - 00:04:38.355] Speaker 2: now a lot of our
[00:04:38.970 - 00:04:39.470] Speaker 2: invention
[00:04:39.850 - 00:04:41.790] Speaker 2: is being done here, whether it's,
[00:04:42.490 - 00:04:43.310] Speaker 2: well, vaccines,
[00:04:43.770 - 00:04:44.270] Speaker 2: obviously,
[00:04:45.290 - 00:04:50.110] Speaker 2: we have some incredible partnerships, but it's broadening to, you know,
[00:04:50.410 - 00:04:52.350] Speaker 2: better seeds, better diagnostics,
[00:04:53.885 - 00:04:56.145] Speaker 2: you know, the ways that we can use AI,
[00:04:56.845 - 00:04:58.145] Speaker 2: for health or education.
[00:04:59.165 - 00:04:59.825] Speaker 2: So the,
[00:05:00.925 - 00:05:01.425] Speaker 2: innovation
[00:05:02.045 - 00:05:04.545] Speaker 2: ecosystem has really exploded, and that's
[00:05:04.845 - 00:05:15.030] Speaker 1: gonna be great for India. It's gonna be great for the world. So when you meet other leaders around the world or when you meet your your billionaire friends, what's the first thing you tell them about India?
[00:05:15.650 - 00:05:17.670] Speaker 1: Is it the same thing that what you just told me?
[00:05:19.090 - 00:05:19.590] Speaker 2: Yeah.
[00:05:21.330 - 00:05:23.625] Speaker 2: It's, you know, we've had such a great
[00:05:24.505 - 00:05:25.005] Speaker 2: experience,
[00:05:25.505 - 00:05:27.005] Speaker 2: in our work in India.
[00:05:28.425 - 00:05:32.045] Speaker 2: You know, I encourage people to come and tap into,
[00:05:32.905 - 00:05:33.865] Speaker 2: the great things,
[00:05:34.265 - 00:05:35.085] Speaker 2: going on.
[00:05:36.050 - 00:05:39.350] Speaker 1: Is there anything specific you tell them? Well, you know, my
[00:05:39.730 - 00:05:45.350] Speaker 2: connection with India goes all the way back to the Microsoft days Yeah. When, you know, we, at first,
[00:05:45.730 - 00:05:56.375] Speaker 2: would hire people from India and bring them to The United States. And, you know, both The United States and India were kinda mad at us because we were taking, you know, the smart people and moving them. And,
[00:05:57.235 - 00:06:00.755] Speaker 2: you know, then they came back here to India and created the Microsoft India,
[00:06:02.300 - 00:06:05.120] Speaker 2: work, which is, you know, been absolutely fantastic.
[00:06:05.980 - 00:06:10.960] Speaker 2: So, you know, up until the year 2000, I mainly knew the tech,
[00:06:12.140 - 00:06:14.080] Speaker 2: scene. So, you know, a lot of
[00:06:14.460 - 00:06:15.680] Speaker 2: Bangalore, Hyderabad,
[00:06:17.325 - 00:06:23.825] Speaker 2: Seeing the country more broadly, you know, that's in my foundation work. So, you know, Bihar, UP,
[00:06:25.805 - 00:06:26.785] Speaker 2: you know, seeing,
[00:06:27.165 - 00:06:30.545] Speaker 2: you know, where we could partner and and help with things.
[00:06:31.880 - 00:06:36.140] Speaker 2: You know, I still wanna take more vacation here. I've done it a little bit, but,
[00:06:36.680 - 00:06:43.740] Speaker 2: you know, there's a lot of great places in India that I haven't been to. Talking about Microsoft and taking people from here to US,
[00:06:44.925 - 00:06:46.625] Speaker 1: people like Satya Della,
[00:06:47.485 - 00:06:48.305] Speaker 1: Sundar Pichai,
[00:06:48.845 - 00:06:51.905] Speaker 1: there have been incredible CEOs around the world.
[00:06:52.445 - 00:06:54.385] Speaker 1: Why do you think India is becoming
[00:06:54.925 - 00:07:01.150] Speaker 1: a global talent capital for the world? Do you think anything special here of which is out there?
[00:07:02.170 - 00:07:03.790] Speaker 2: Well, you know, 20%
[00:07:04.730 - 00:07:09.950] Speaker 2: of the world's people live here in India. And India's had a particular emphasis on,
[00:07:10.445 - 00:07:11.265] Speaker 2: you know, engineering,
[00:07:12.205 - 00:07:12.705] Speaker 2: software,
[00:07:13.005 - 00:07:16.225] Speaker 2: you know, and turned out a lot of top people.
[00:07:16.685 - 00:07:18.625] Speaker 2: And so when you get people like
[00:07:19.005 - 00:07:23.025] Speaker 2: Sundar Satya, who are both great at engineering and management,
[00:07:23.980 - 00:07:25.840] Speaker 2: you know, that's a a magic,
[00:07:26.860 - 00:07:27.360] Speaker 2: combination.
[00:07:28.380 - 00:07:28.880] Speaker 2: And,
[00:07:29.580 - 00:07:32.240] Speaker 2: you know, so they you know, these companies,
[00:07:32.860 - 00:07:35.520] Speaker 2: you know, are looking anywhere in the world to find,
[00:07:36.940 - 00:07:39.925] Speaker 2: that mix. And, you know, so India's getting
[00:07:40.465 - 00:07:43.685] Speaker 2: about its fair share of those top leadership positions.
[00:07:44.305 - 00:07:46.245] Speaker 2: And, you know, it partly comes from having
[00:07:46.545 - 00:07:47.445] Speaker 2: great universities,
[00:07:49.025 - 00:07:52.485] Speaker 2: you know, not just the IITs, but starting with them,
[00:07:54.370 - 00:07:55.190] Speaker 2: you know, that's
[00:07:55.650 - 00:07:58.550] Speaker 2: using the incredible talent that's here.
[00:07:59.570 - 00:08:01.510] Speaker 1: So talking about Indian talent,
[00:08:02.450 - 00:08:08.310] Speaker 1: you do a lot of philanthropy work here, and you've met a lot of talented people here, a lot of
[00:08:08.625 - 00:08:10.165] Speaker 1: rich people here as well.
[00:08:11.345 - 00:08:27.810] Speaker 1: Do you and you believe that all the money that rich people have or, like, people who have made well for themselves, they should use it for charity work. They should pledge it. In India, there's a usually lot of people believe that as parents is their duty to save everything for their kids
[00:08:28.110 - 00:08:34.450] Speaker 1: for the inheritance, right? Like the kids will get everything. What do you think is the right mindset using all the money for
[00:08:35.095 - 00:08:38.795] Speaker 1: pledging and giving it back to the society or giving it to the children?
[00:08:40.135 - 00:08:41.115] Speaker 2: Well, I think,
[00:08:41.575 - 00:08:45.195] Speaker 2: you know, everybody gets to decide on that. You know, in my case,
[00:08:45.575 - 00:08:46.635] Speaker 2: you know, my kids
[00:08:47.495 - 00:08:47.970] Speaker 2: got
[00:08:49.810 - 00:08:50.550] Speaker 2: a great
[00:08:51.330 - 00:08:53.590] Speaker 2: upbringing in education, but, you know,
[00:08:53.970 - 00:08:55.350] Speaker 2: less than 1%
[00:08:55.410 - 00:08:56.070] Speaker 2: of the,
[00:08:57.650 - 00:08:58.790] Speaker 2: the total wealth,
[00:08:59.730 - 00:09:11.465] Speaker 2: because I decided it wouldn't be a favor to them. You You know, it's not a dynasty. You know, I'm not asking them to run Microsoft. I wanna give them a chance to have their own earnings and success,
[00:09:12.005 - 00:09:15.145] Speaker 2: you know, be significant and not overshadowed by
[00:09:15.445 - 00:09:16.980] Speaker 2: the incredible luck
[00:09:17.540 - 00:09:21.880] Speaker 2: and good fortune I had. And different families see that differently. I think the
[00:09:22.340 - 00:09:23.480] Speaker 2: people who've made,
[00:09:24.260 - 00:09:25.480] Speaker 2: fortunes from technology
[00:09:26.500 - 00:09:27.720] Speaker 2: are less dynastic,
[00:09:29.540 - 00:09:31.400] Speaker 2: and, you know, so they
[00:09:31.945 - 00:09:35.005] Speaker 2: they'll even, you know, take their capital
[00:09:35.625 - 00:09:41.165] Speaker 2: and give a lot of that away. You can have the view of giving away your capital or just giving away your earnings.
[00:09:42.425 - 00:09:44.445] Speaker 2: And and, of course, I love all philanthropy,
[00:09:45.690 - 00:09:48.910] Speaker 2: but the tech sector is the probably the most aggressive
[00:09:49.290 - 00:09:49.790] Speaker 2: about,
[00:09:51.290 - 00:09:53.550] Speaker 2: you know, giving most of it away.
[00:09:54.010 - 00:10:02.145] Speaker 1: And are there other sectors you have not seen that in any other kind of industry where people try to give Not not to the same degree. It tends to be,
[00:10:02.925 - 00:10:06.865] Speaker 2: giving more, you know, of the giving some portion of the profit
[00:10:07.725 - 00:10:08.945] Speaker 2: as opposed to,
[00:10:10.125 - 00:10:11.985] Speaker 2: the the actual base capital.
[00:10:12.445 - 00:10:14.000] Speaker 1: You know, in India,
[00:10:14.700 - 00:10:18.240] Speaker 1: a lot of kids also fight their with their parents on the inheritance.
[00:10:18.540 - 00:10:24.960] Speaker 1: Have your kids ever spoken to you and be like, hey, why are you not giving us everything or anything? Has it ever happened?
[00:10:26.785 - 00:10:29.605] Speaker 2: You know, you don't want your kids to ever be confused
[00:10:30.785 - 00:10:36.085] Speaker 2: about your support for them and your love for them. And so I do think explaining early on
[00:10:37.025 - 00:10:37.845] Speaker 2: your philosophy,
[00:10:39.600 - 00:10:41.540] Speaker 2: that you're gonna treat them all equally,
[00:10:42.480 - 00:10:44.820] Speaker 2: and that you're gonna give them incredible opportunities,
[00:10:46.240 - 00:10:48.580] Speaker 2: but that, you know, the highest calling,
[00:10:49.440 - 00:10:50.500] Speaker 2: for these resources
[00:10:50.880 - 00:10:51.380] Speaker 2: is,
[00:10:52.240 - 00:10:53.140] Speaker 2: to go back,
[00:10:54.545 - 00:10:55.365] Speaker 2: to the neediest
[00:10:56.065 - 00:10:57.125] Speaker 2: through the foundation.
[00:10:57.665 - 00:11:02.725] Speaker 2: And, you know, they've seen the success of the foundation. I hope they're very proud
[00:11:03.425 - 00:11:05.425] Speaker 2: of of the foundation. And,
[00:11:07.585 - 00:11:08.085] Speaker 2: so,
[00:11:08.860 - 00:11:12.400] Speaker 2: you know, I I've seen cases where kids actually tell their parents
[00:11:12.780 - 00:11:13.840] Speaker 2: to be more philanthropic.
[00:11:14.220 - 00:11:16.880] Speaker 2: You know, I think the younger generation sometimes actually,
[00:11:18.380 - 00:11:21.280] Speaker 2: is pushing against this idea of of,
[00:11:23.020 - 00:11:25.925] Speaker 2: you know, the wealth just being passed down,
[00:11:27.025 - 00:11:27.525] Speaker 2: mostly.
[00:11:29.825 - 00:11:39.845] Speaker 1: And So that's So to, you know, every family is a a bit different. I have last question on India, and then we'll get to the foundation work and try to understand you as well.
[00:11:40.980 - 00:11:42.360] Speaker 1: If you get an opportunity
[00:11:43.940 - 00:11:45.640] Speaker 1: to invite three Indians
[00:11:46.260 - 00:11:47.080] Speaker 1: for dinner,
[00:11:47.700 - 00:11:49.960] Speaker 1: dead or alive, who would that be?
[00:11:51.780 - 00:11:54.680] Speaker 2: Well, I get to spend time with, you know, some incredible,
[00:11:55.995 - 00:12:00.815] Speaker 2: people in India and, you know, I get time with the prime minister and understand his vision,
[00:12:02.155 - 00:12:05.695] Speaker 2: and how we fit into that. This, you know, 2047,
[00:12:07.595 - 00:12:12.860] Speaker 2: thing that, you know, everything is lining up to try to achieve that. You know, I get to meet,
[00:12:13.900 - 00:12:19.600] Speaker 2: there was a great scientist, Raj Baughn, who created the, Department of Biotechnology.
[00:12:21.340 - 00:12:22.320] Speaker 2: There was a mathematician,
[00:12:23.100 - 00:12:23.600] Speaker 2: Ramanujan,
[00:12:25.155 - 00:12:27.975] Speaker 2: who I would have loved to have met him because he was,
[00:12:28.995 - 00:12:30.615] Speaker 2: you know, almost mysterious
[00:12:30.995 - 00:12:32.135] Speaker 2: how he was so
[00:12:32.675 - 00:12:35.475] Speaker 2: genius at what he was able to do.
[00:12:37.155 - 00:12:38.215] Speaker 2: You know, the,
[00:12:38.740 - 00:12:42.680] Speaker 2: I got to work with Rotten Todd. I'm getting to work with all of the,
[00:12:43.940 - 00:12:45.160] Speaker 2: amazing philanthropists
[00:12:45.540 - 00:12:46.040] Speaker 2: and,
[00:12:46.820 - 00:12:50.120] Speaker 2: a lot of the innovators here. You know, I get to see small companies
[00:12:50.500 - 00:12:52.120] Speaker 2: early on. I just went through,
[00:12:52.935 - 00:12:53.895] Speaker 2: some of these,
[00:12:54.295 - 00:12:55.675] Speaker 2: companies using AI
[00:12:55.975 - 00:12:56.715] Speaker 2: in health.
[00:12:57.415 - 00:12:59.515] Speaker 2: Some prop for profit, a few,
[00:13:00.615 - 00:13:01.115] Speaker 2: nonprofit.
[00:13:03.095 - 00:13:04.955] Speaker 2: You know, we had a great twenty fifth,
[00:13:07.640 - 00:13:11.420] Speaker 2: twenty five year celebration and this great, sitar artist,
[00:13:11.880 - 00:13:15.580] Speaker 2: you know, came and, that was a pretty special thing.
[00:13:16.120 - 00:13:19.740] Speaker 2: So it'd be hard for me to pick. There's there's, so many
[00:13:20.115 - 00:13:22.695] Speaker 1: incredible talents. You can't pick three.
[00:13:23.875 - 00:13:25.415] Speaker 2: I I I think I defend,
[00:13:25.955 - 00:13:26.615] Speaker 2: some people
[00:13:28.835 - 00:13:30.135] Speaker 2: by not including them.
[00:13:30.675 - 00:13:31.655] Speaker 1: Fair. Fair.
[00:13:32.915 - 00:13:35.100] Speaker 1: You were talking about small companies. If
[00:13:35.740 - 00:13:37.920] Speaker 1: you were to start something from zero
[00:13:38.460 - 00:13:39.840] Speaker 1: in India today, where
[00:13:41.100 - 00:13:41.760] Speaker 1: would you
[00:13:42.140 - 00:13:47.600] Speaker 1: put most of your time? And what the first step you'll take? Well, you'd mostly start a company because you think
[00:13:48.065 - 00:13:54.245] Speaker 2: you enjoy working on something and you think you have a world class understanding of, you know, a unique contribution.
[00:13:55.105 - 00:13:56.885] Speaker 2: You know, for me, that was software.
[00:13:57.665 - 00:14:00.405] Speaker 2: For this day and age, you know, if you think you understand,
[00:14:00.840 - 00:14:01.820] Speaker 2: you know, fusion,
[00:14:03.000 - 00:14:05.660] Speaker 2: you know, that's great. If you're successful, which,
[00:14:06.200 - 00:14:07.100] Speaker 2: that's risky,
[00:14:08.600 - 00:14:13.180] Speaker 2: you know, you could really improve the world. You know, AI is sort of the
[00:14:14.275 - 00:14:18.135] Speaker 2: today's equivalent of what I did when I was young to see,
[00:14:18.515 - 00:14:21.095] Speaker 2: you know, wow, the possibilities
[00:14:21.555 - 00:14:22.055] Speaker 2: are
[00:14:22.435 - 00:14:22.935] Speaker 2: unlimited.
[00:14:24.435 - 00:14:26.775] Speaker 2: And so, you know, I'd probably be doing,
[00:14:27.750 - 00:14:34.490] Speaker 2: one of these new AI companies if I was starting out today. Is it do you still feel there's opportunity,
[00:14:34.870 - 00:14:38.890] Speaker 1: a lot of opportunities in AI to build something as significant as what you have built
[00:14:39.285 - 00:14:41.465] Speaker 1: or it's pretty late? Well,
[00:14:42.005 - 00:14:43.225] Speaker 2: you know, the big companies
[00:14:43.685 - 00:14:44.185] Speaker 2: are,
[00:14:45.525 - 00:14:47.465] Speaker 2: putting a lot of money into it.
[00:14:48.885 - 00:14:50.745] Speaker 2: And the number of companies globally
[00:14:51.845 - 00:15:05.290] Speaker 2: is is, you know, huge. I mean, you know, many people didn't even know these Chinese companies who were doing all this work and yet Yeah. You know, some of the best results over the last six months have come from three or four of the models there.
[00:15:05.670 - 00:15:06.645] Speaker 2: So it's not,
[00:15:07.205 - 00:15:18.905] Speaker 2: when I got going in computing, it was a very small set of people. And, you know, people thought we were crazy that there we set a computer on every desk and a computer in every home.
[00:15:19.410 - 00:15:25.830] Speaker 2: And that just seemed strange to people because they couldn't see the they didn't get software and they didn't get the,
[00:15:26.770 - 00:15:27.270] Speaker 2: exponential
[00:15:27.570 - 00:15:28.070] Speaker 2: improvement
[00:15:28.770 - 00:15:32.150] Speaker 2: of the chips was making computing, you know, basically
[00:15:32.530 - 00:15:33.030] Speaker 2: free.
[00:15:33.890 - 00:15:36.255] Speaker 2: So it's I'd say it's tougher,
[00:15:39.035 - 00:15:40.415] Speaker 2: to get out in front.
[00:15:40.875 - 00:15:41.195] Speaker 2: Mhmm.
[00:15:41.915 - 00:15:44.495] Speaker 2: There will be new companies. I mean, Nvidia,
[00:15:44.875 - 00:15:47.455] Speaker 2: you know, is almost as valuable as,
[00:15:48.075 - 00:15:49.215] Speaker 2: Apple and Microsoft.
[00:15:50.155 - 00:15:50.975] Speaker 2: And yet,
[00:15:52.370 - 00:15:53.110] Speaker 2: you know, they,
[00:15:53.570 - 00:15:54.070] Speaker 2: they,
[00:15:54.450 - 00:15:59.110] Speaker 2: you know, came into prominence only really in the last five or six years, although they're about
[00:15:59.570 - 00:16:02.230] Speaker 2: 15 years old. So there are opportunities
[00:16:02.610 - 00:16:06.390] Speaker 2: and there will be some new companies that use AI,
[00:16:07.595 - 00:16:12.255] Speaker 2: to achieve unbelievable success, but it'll be, you know, two or three out of 10,000.
[00:16:12.875 - 00:16:15.375] Speaker 2: And, you know, would I be able to do that again?
[00:16:15.835 - 00:16:18.335] Speaker 2: Hard to say. You talked about,
[00:16:18.795 - 00:16:33.080] Speaker 1: like, when you started, a lot of people thought that, oh, what are you doing? This is some random thing these guys are trying to do. They may be stupid. They may be thinking too big. Whatever. Right? And over the time, every time you do something big, usually
[00:16:33.700 - 00:16:34.200] Speaker 1: people
[00:16:35.075 - 00:16:40.775] Speaker 1: do not understand you or anyone, like, not just you, like, whoever wants to start something new and big.
[00:16:41.475 - 00:16:45.495] Speaker 1: In today's world, or as of today, what's the biggest misunderstanding
[00:16:46.195 - 00:16:47.010] Speaker 1: about you?
[00:16:48.050 - 00:16:51.270] Speaker 1: What do you think? What do people misunderstand about Bill Gates?
[00:16:51.890 - 00:16:54.150] Speaker 2: Well, whenever you hear about somebody who's got,
[00:16:54.690 - 00:16:57.270] Speaker 2: you know, some degree of power or,
[00:16:57.890 - 00:17:00.070] Speaker 2: you know, ridiculous amounts of money,
[00:17:00.975 - 00:17:03.875] Speaker 2: you know, might you might think they have grand schemes,
[00:17:04.735 - 00:17:05.875] Speaker 2: you know, and they're,
[00:17:07.295 - 00:17:12.355] Speaker 2: you know, there's almost a sense that, you know, their their values are different
[00:17:12.895 - 00:17:17.630] Speaker 2: than your values and, you know, that you should be concerned about their agenda.
[00:17:19.290 - 00:17:20.190] Speaker 2: You know, hopefully,
[00:17:20.650 - 00:17:22.670] Speaker 2: for the people who actually do know me,
[00:17:23.690 - 00:17:25.310] Speaker 2: you know, and how much I love,
[00:17:26.010 - 00:17:26.750] Speaker 2: the foundation
[00:17:27.050 - 00:17:30.885] Speaker 2: work and, you know, how I work with my friends or my kids,
[00:17:31.825 - 00:17:33.205] Speaker 2: you know, it's very different
[00:17:33.665 - 00:17:39.685] Speaker 2: from the people who just think, oh, wow. You know, he's one of these guys who's, you know, pushing levers and,
[00:17:40.705 - 00:17:43.230] Speaker 2: has has too much money and and too much,
[00:17:44.030 - 00:17:44.530] Speaker 2: authority.
[00:17:45.390 - 00:17:46.610] Speaker 1: So that people misunderstand
[00:17:46.990 - 00:17:47.730] Speaker 1: about you.
[00:17:49.230 - 00:17:54.770] Speaker 1: And tell you on misunderstanding, do you have you made any major mistake that people don't know about?
[00:17:55.895 - 00:17:58.555] Speaker 2: Well, some of my mistakes are very public. I mean, Microsoft,
[00:17:59.815 - 00:18:05.115] Speaker 2: you know, we had lots of products that didn't work. You know, we did a a phone operating system, and now,
[00:18:05.895 - 00:18:06.955] Speaker 2: you know, Android,
[00:18:07.335 - 00:18:09.915] Speaker 2: you know, took that position. So I certainly,
[00:18:10.460 - 00:18:12.240] Speaker 2: you know, messed that up,
[00:18:14.860 - 00:18:16.640] Speaker 2: in a huge way.
[00:18:17.260 - 00:18:18.080] Speaker 2: For the foundation,
[00:18:18.700 - 00:18:21.840] Speaker 2: you know, we often have multiple plans. You know, we
[00:18:22.220 - 00:18:24.000] Speaker 2: wanted to have an HIV vaccine.
[00:18:25.145 - 00:18:28.685] Speaker 2: We don't have that yet. You know, we're working on a very cheap
[00:18:29.065 - 00:18:31.645] Speaker 2: toilet, but it's still too expensive.
[00:18:32.265 - 00:18:34.685] Speaker 2: So that's taking a lot longer. We don't have polio
[00:18:35.225 - 00:18:36.845] Speaker 2: eradication done. I'm still,
[00:18:37.865 - 00:18:41.190] Speaker 2: very committed to that, but it's taking a lot longer,
[00:18:42.050 - 00:18:43.830] Speaker 2: than than we thought it would.
[00:18:44.130 - 00:18:47.030] Speaker 1: So do you talking about Foundation work, you've
[00:18:47.490 - 00:18:49.510] Speaker 1: impacted millions of life
[00:18:49.890 - 00:18:54.070] Speaker 1: and you spend a lot in making people's life better.
[00:18:54.985 - 00:18:56.685] Speaker 1: What's your biggest challenge today?
[00:18:57.625 - 00:18:58.125] Speaker 1: Because
[00:18:58.585 - 00:18:59.085] Speaker 1: somebody
[00:18:59.865 - 00:19:05.085] Speaker 1: on somebody who's watching this might think that at your level with so much
[00:19:05.785 - 00:19:09.245] Speaker 1: power influence money. You can actually fix a lot of problems.
[00:19:09.620 - 00:19:13.000] Speaker 1: What do you think is your problem? Like, what challenges do you see here?
[00:19:13.940 - 00:19:15.400] Speaker 2: Well, I'm I love the
[00:19:15.940 - 00:19:18.360] Speaker 2: scientific challenges. I mean, we still don't
[00:19:18.820 - 00:19:19.640] Speaker 2: fully understand
[00:19:20.260 - 00:19:20.760] Speaker 2: malnutrition.
[00:19:22.115 - 00:19:25.735] Speaker 2: We have some tools to reduce it that it's super exciting.
[00:19:26.755 - 00:19:28.695] Speaker 2: But, you know, I'm really pushing our
[00:19:29.235 - 00:19:29.735] Speaker 2: research
[00:19:30.035 - 00:19:30.535] Speaker 2: workers,
[00:19:31.875 - 00:19:32.855] Speaker 2: hard that,
[00:19:33.155 - 00:19:37.255] Speaker 2: okay, you know, we need we need to know more about that.
[00:19:38.170 - 00:19:39.390] Speaker 2: You know, I do think
[00:19:39.690 - 00:19:43.630] Speaker 2: getting money to help the very poorest countries, a lot of which are in Africa.
[00:19:43.930 - 00:19:44.910] Speaker 2: You know, Asia,
[00:19:45.450 - 00:19:46.030] Speaker 2: you know,
[00:19:47.530 - 00:19:50.750] Speaker 2: many of the countries are having good economic
[00:19:51.050 - 00:19:52.670] Speaker 2: growth. And and Africa
[00:19:53.645 - 00:19:54.445] Speaker 2: has a lot of unique,
[00:19:56.525 - 00:19:57.025] Speaker 2: governments
[00:19:57.325 - 00:19:58.385] Speaker 2: or instability
[00:19:59.405 - 00:20:01.585] Speaker 2: or disease challenges. And so
[00:20:02.925 - 00:20:05.825] Speaker 2: telling people they should, you know, help out,
[00:20:06.925 - 00:20:10.890] Speaker 2: other humans even though they're they're far away and speak a different language.
[00:20:12.310 - 00:20:14.550] Speaker 2: That's not as easy as I thought it would be.
[00:20:15.350 - 00:20:19.610] Speaker 2: You know, right now, some of the rich countries, including my country, are cutting their aid budgets.
[00:20:20.070 - 00:20:21.850] Speaker 2: And I'm I'm very disappointed
[00:20:22.310 - 00:20:24.485] Speaker 2: that, you know, to me, that's not,
[00:20:24.945 - 00:20:26.725] Speaker 2: you know, the golden rule of
[00:20:27.025 - 00:20:30.805] Speaker 2: treating people like you'd like to be treated. So what do you think
[00:20:31.185 - 00:20:33.525] Speaker 1: all the people who are watching this, including me,
[00:20:34.305 - 00:20:38.940] Speaker 1: young people should do so that we could convince more people to help other people.
[00:20:39.320 - 00:20:40.860] Speaker 2: Well, when you're young,
[00:20:42.440 - 00:20:45.260] Speaker 2: if you're here in India, you know, you can probably travel,
[00:20:46.120 - 00:20:48.780] Speaker 2: you know, some modest distance an hour or two
[00:20:49.125 - 00:20:52.265] Speaker 2: and see people, you know, who don't have the same
[00:20:52.645 - 00:20:57.785] Speaker 2: opportunities you do. That, you know, they're smart, but their school's not good or, you know, they get,
[00:20:58.805 - 00:21:01.465] Speaker 2: some health problem and they're not able to access
[00:21:02.005 - 00:21:07.570] Speaker 2: things. I would say in India, you know, programs like the aspirational district program,
[00:21:08.190 - 00:21:09.090] Speaker 2: India does,
[00:21:10.110 - 00:21:11.010] Speaker 2: talk openly
[00:21:11.710 - 00:21:16.050] Speaker 2: about the places that are the worst off. And that's, you know, that's pretty impressive.
[00:21:17.015 - 00:21:19.675] Speaker 2: You know, even issues like sanitation that governments
[00:21:20.215 - 00:21:24.775] Speaker 2: most governments, you know, you wouldn't catch them talking about toilets. Yeah.
[00:21:25.335 - 00:21:26.315] Speaker 2: You know, this
[00:21:26.695 - 00:21:29.675] Speaker 2: country, you know, took on a pretty aggressive
[00:21:30.215 - 00:21:31.195] Speaker 2: plan and made
[00:21:31.575 - 00:21:35.410] Speaker 2: a lot of progress on that. So you can go out and see,
[00:21:36.910 - 00:21:38.610] Speaker 2: people and develop empathy,
[00:21:39.150 - 00:21:40.770] Speaker 2: without going too far.
[00:21:42.190 - 00:21:42.690] Speaker 2: And
[00:21:43.230 - 00:21:44.050] Speaker 2: you spent
[00:21:45.705 - 00:21:48.605] Speaker 1: hours and hours and days in this country.
[00:21:48.985 - 00:21:49.645] Speaker 1: You spent
[00:21:50.505 - 00:21:54.445] Speaker 1: millions on vaccines and trying to take care of health care challenges.
[00:21:55.385 - 00:21:59.325] Speaker 1: What's one problem you feel that money cannot fix?
[00:22:02.660 - 00:22:04.260] Speaker 2: You know, there's a lot of talk about,
[00:22:05.940 - 00:22:06.440] Speaker 2: obesity
[00:22:07.300 - 00:22:07.800] Speaker 2: and,
[00:22:09.140 - 00:22:18.615] Speaker 2: you know, when I saw the prime minister, he was talking about various yoga type things that, you know, people would adopt those. But it's been hard, you know, not many countries
[00:22:19.315 - 00:22:24.855] Speaker 2: have gotten the behavior change. Yeah. You know, maybe India can pioneer some approaches there,
[00:22:25.235 - 00:22:26.520] Speaker 2: but, you know, frankly,
[00:22:26.980 - 00:22:31.080] Speaker 2: and I'll sound like a technologist, the most promising thing is actually,
[00:22:33.300 - 00:22:34.520] Speaker 2: you know, a drug,
[00:22:34.900 - 00:22:46.855] Speaker 2: a class of drugs called these GLP one drugs that, you know, are going to go off patent and become cheap and, you know, so I always like, you know, I'm a little over focused on a scientific solution.
[00:22:47.235 - 00:22:53.220] Speaker 2: So maybe a combination of that behavior change and, and the new tools, but behavior change is hard.
[00:22:54.500 - 00:22:56.200] Speaker 2: We we haven't,
[00:22:57.700 - 00:23:02.920] Speaker 2: succeeded in that as as much as we'd like to. Tell me one behavior we all should adopt.
[00:23:03.940 - 00:23:04.440] Speaker 2: Well,
[00:23:04.740 - 00:23:09.275] Speaker 2: you know, the behavior that's helped me is is basically being a student
[00:23:09.815 - 00:23:12.395] Speaker 2: all the time, wanting to learn things and being pretty
[00:23:13.255 - 00:23:15.675] Speaker 2: brutal with myself of, do I really understand,
[00:23:16.215 - 00:23:19.435] Speaker 2: you know, what's going on? You know, do I understand
[00:23:20.050 - 00:23:21.650] Speaker 2: some AI thing or,
[00:23:23.170 - 00:23:25.910] Speaker 2: some disease thing? And, you know, fortunately,
[00:23:27.570 - 00:23:29.270] Speaker 2: I can meet with people who
[00:23:29.650 - 00:23:39.105] Speaker 2: in many cases can help me understand. And then, you know, knowledge, if you're careful about building your your knowledge, it all kind of connects together. But,
[00:23:39.885 - 00:23:44.705] Speaker 2: you know, reading a lot, being a student, you know, having people who can teach me,
[00:23:46.285 - 00:23:46.785] Speaker 2: that's,
[00:23:47.405 - 00:23:48.145] Speaker 2: you know,
[00:23:48.570 - 00:23:50.990] Speaker 2: been not only fun for me, but also
[00:23:51.370 - 00:23:52.910] Speaker 2: a big part of my success.
[00:23:54.170 - 00:23:56.670] Speaker 1: So all of people who are watching this
[00:23:57.050 - 00:23:59.550] Speaker 1: actually feels pretty validated at this point.
[00:24:00.010 - 00:24:00.510] Speaker 1: Good.
[00:24:00.970 - 00:24:04.185] Speaker 1: Because this whole pod cause is about learning
[00:24:04.565 - 00:24:07.305] Speaker 1: from really really incredible people like you.
[00:24:07.605 - 00:24:08.505] Speaker 1: And we have
[00:24:08.805 - 00:24:15.545] Speaker 1: so many questions that we just keep asking to learn more to learn more to get inside brain. So thanks for validation.
[00:24:16.565 - 00:24:17.065] Speaker 1: Perfect.
[00:24:18.600 - 00:24:23.340] Speaker 1: What's fascinating for me, this time in your journey, like, this time you visit to India,
[00:24:24.280 - 00:24:29.900] Speaker 1: the full Gates Foundation board is here. Right? And that's pretty unique, and they get to experience India.
[00:24:31.465 - 00:24:33.405] Speaker 1: What what do you think? What are your priorities
[00:24:34.585 - 00:24:36.205] Speaker 1: with regards to this nation?
[00:24:36.745 - 00:24:42.525] Speaker 1: Why the whole board is here? What do you guys are trying to figure out? What are the things that you're doing?
[00:24:43.065 - 00:24:44.365] Speaker 2: Well, as much progress
[00:24:44.900 - 00:24:46.280] Speaker 2: as we've been part
[00:24:47.300 - 00:24:50.200] Speaker 2: of achieving here in India, there's still a lot to do.
[00:24:51.380 - 00:24:56.680] Speaker 2: You know, the the child to death rate is about a third of what it was,
[00:24:57.705 - 00:24:58.605] Speaker 2: but it's still
[00:24:58.985 - 00:25:00.605] Speaker 2: almost three times higher
[00:25:01.065 - 00:25:02.445] Speaker 2: than in a rich country.
[00:25:03.065 - 00:25:06.685] Speaker 2: So we, you know, we should all want to close that gap. That's,
[00:25:08.025 - 00:25:08.525] Speaker 2: equity.
[00:25:09.305 - 00:25:10.365] Speaker 2: I mentioned malnutrition.
[00:25:11.890 - 00:25:15.330] Speaker 2: You know, the country is very serious about that and yet,
[00:25:16.290 - 00:25:20.310] Speaker 2: you know, it means that your brain never develops. And sadly,
[00:25:21.170 - 00:25:22.310] Speaker 2: if whatever
[00:25:23.090 - 00:25:25.270] Speaker 2: dietary or disease things
[00:25:25.730 - 00:25:26.630] Speaker 2: affect you,
[00:25:27.765 - 00:25:29.865] Speaker 2: during pregnancy in your first year,
[00:25:30.325 - 00:25:31.305] Speaker 2: even if later
[00:25:31.685 - 00:25:34.745] Speaker 2: you get a fantastic diet, your brain
[00:25:35.045 - 00:25:36.265] Speaker 2: and your physical,
[00:25:37.525 - 00:25:38.025] Speaker 2: capabilities,
[00:25:38.325 - 00:25:39.065] Speaker 2: they don't
[00:25:39.445 - 00:25:42.960] Speaker 2: adjust. You're, you know, sort of permanently affected. And so,
[00:25:44.640 - 00:25:50.900] Speaker 2: you know, we're working with some great scientists here. We have a lot of the tools of biology have gotten a lot better. So I do think,
[00:25:52.560 - 00:25:56.260] Speaker 2: you know, in the next decade we'll totally get to the bottom of that.
[00:25:57.795 - 00:26:00.855] Speaker 2: And, you know, I'm I'm thrilled to do that. And a lot of
[00:26:01.955 - 00:26:05.575] Speaker 2: the scientists we partner with, you know, including some at ICMR,
[00:26:05.955 - 00:26:08.535] Speaker 2: but, you know, lots of institutions around the country,
[00:26:09.715 - 00:26:10.535] Speaker 2: they're also,
[00:26:11.235 - 00:26:12.210] Speaker 2: committed to that.
[00:26:12.930 - 00:26:13.830] Speaker 1: So you
[00:26:14.210 - 00:26:17.590] Speaker 1: work here a lot and with the foundation you work around the world,
[00:26:17.890 - 00:26:21.190] Speaker 1: a lot of things. And because of all of this
[00:26:21.730 - 00:26:26.630] Speaker 1: passion and data and this intention to try to help people,
[00:26:27.335 - 00:26:30.955] Speaker 1: you've been pretty accurate in trying to understand trends
[00:26:31.575 - 00:26:32.635] Speaker 1: way before people,
[00:26:32.935 - 00:26:37.755] Speaker 1: like, normal people. Let's say, you're pretty accurate in so many things in predicting
[00:26:38.775 - 00:26:43.290] Speaker 1: so many epidemics as well. Is there something that you'd know which we don't?
[00:26:45.030 - 00:26:48.090] Speaker 1: Like, how do you spot these things way faster?
[00:26:48.470 - 00:26:50.650] Speaker 2: Well, the biggest change agent
[00:26:51.430 - 00:26:52.490] Speaker 2: in my lifetime
[00:26:53.270 - 00:26:55.530] Speaker 2: has been the the miracle of digital.
[00:26:55.910 - 00:26:56.890] Speaker 2: You know, now,
[00:26:58.185 - 00:27:04.205] Speaker 2: moving into the AI phase of of that digital revolution. So the fact that as a young person,
[00:27:04.825 - 00:27:05.725] Speaker 2: you know, I was
[00:27:06.025 - 00:27:08.845] Speaker 2: programming at age 13 and by,
[00:27:09.200 - 00:27:13.300] Speaker 2: you know, 18, I had my, you know, thousands of hours of,
[00:27:14.400 - 00:27:17.860] Speaker 2: really strong feedback about, you know, getting better and,
[00:27:18.880 - 00:27:19.700] Speaker 2: being pushed.
[00:27:21.200 - 00:27:24.805] Speaker 2: And so to, it's a really lucky thing
[00:27:25.505 - 00:27:27.205] Speaker 2: to have such a
[00:27:28.225 - 00:27:28.725] Speaker 2: familiarity
[00:27:29.665 - 00:27:36.645] Speaker 2: with the thing that's going to change the world. And so, you know, I wrote a book called The Road Ahead a long time ago,
[00:27:37.070 - 00:27:38.530] Speaker 2: you know, that talked about,
[00:27:39.150 - 00:27:42.290] Speaker 2: you know, the internet and digital money and,
[00:27:43.070 - 00:27:44.130] Speaker 2: video conferencing.
[00:27:45.390 - 00:27:54.005] Speaker 2: And then when I moved into the foundation work, the health work, you know, people in that community understand pandemics and, you know, so my saying,
[00:27:54.305 - 00:27:57.685] Speaker 2: hey, you know, there's a big risk and the thing that's gonna
[00:27:58.145 - 00:27:58.645] Speaker 2: kill,
[00:27:58.945 - 00:28:02.725] Speaker 2: you know, ten million additional people is likely to be a pandemic.
[00:28:04.385 - 00:28:09.500] Speaker 2: You know, that's common place knowledge if you're in the global health community. It's a very small community.
[00:28:10.520 - 00:28:13.580] Speaker 2: But I was just somebody who was listened to,
[00:28:15.720 - 00:28:16.220] Speaker 2: stating,
[00:28:17.400 - 00:28:18.700] Speaker 2: this. And sadly,
[00:28:19.375 - 00:28:21.875] Speaker 2: you know, most of the people who listen to that prediction,
[00:28:22.815 - 00:28:24.755] Speaker 2: listen to it after it came true.
[00:28:25.295 - 00:28:28.995] Speaker 2: Then, you know, what my goal was was people to hear that and actually,
[00:28:30.415 - 00:28:34.995] Speaker 1: stop it from happening. That's usually the case. Right? Like, people listen to
[00:28:36.120 - 00:28:36.620] Speaker 1: pieces,
[00:28:36.920 - 00:28:41.340] Speaker 1: golden eduise pieces and pieces of nuggets way after the time has been passed.
[00:28:42.680 - 00:28:43.820] Speaker 1: Right? Because of this,
[00:28:44.360 - 00:28:47.020] Speaker 1: do you fear anything today? I definitely
[00:28:47.675 - 00:28:49.775] Speaker 2: hope that we shape AI
[00:28:50.875 - 00:28:53.295] Speaker 2: in a positive way. It's such a
[00:28:53.835 - 00:28:54.335] Speaker 2: big,
[00:28:55.595 - 00:28:56.095] Speaker 2: impact
[00:28:56.555 - 00:28:57.055] Speaker 2: on,
[00:28:57.675 - 00:28:58.255] Speaker 2: you know,
[00:28:58.955 - 00:29:00.575] Speaker 2: being smarter than humans,
[00:29:01.675 - 00:29:02.895] Speaker 2: that it will change
[00:29:03.520 - 00:29:04.740] Speaker 2: our world a lot.
[00:29:06.240 - 00:29:13.060] Speaker 2: And it's, you know, it's it's definitely new territory. So I have a list of about five things, you know, AI, shaping AI properly
[00:29:13.600 - 00:29:16.260] Speaker 2: is at the top of that list. But, you know, avoiding
[00:29:16.755 - 00:29:19.255] Speaker 2: the next pandemic, avoiding nuclear war,
[00:29:20.115 - 00:29:20.615] Speaker 2: bioterrorism,
[00:29:21.315 - 00:29:25.575] Speaker 2: climate change. It's only about five or six things that we need to,
[00:29:27.475 - 00:29:27.975] Speaker 2: minimize
[00:29:28.835 - 00:29:30.055] Speaker 2: the chance of,
[00:29:31.110 - 00:29:32.570] Speaker 2: you know, and use our
[00:29:32.950 - 00:29:34.810] Speaker 2: additional wealth and insights,
[00:29:35.270 - 00:29:45.995] Speaker 2: you know, against those things. Do you have any personal fear? What's your biggest fear? You know, it's not like I'm afraid of heights or planes or fire or anything like that. You know, I hope I'm
[00:29:46.615 - 00:29:48.315] Speaker 2: I'll be sad as my brain,
[00:29:50.055 - 00:29:51.275] Speaker 2: gets less capable,
[00:29:51.655 - 00:29:57.915] Speaker 2: you know, which, you know, as I turn 70 this year, you know, I'd be lucky to have twenty
[00:29:58.560 - 00:30:01.220] Speaker 2: years of, you know, being able to learn,
[00:30:01.840 - 00:30:07.460] Speaker 2: you know, maybe I'll get lucky and get a little bit more. But, you know, that disappoints me because I've
[00:30:07.840 - 00:30:08.660] Speaker 2: had such
[00:30:09.440 - 00:30:11.060] Speaker 2: a amazing time learning,
[00:30:12.400 - 00:30:16.195] Speaker 2: things. And I I used to think of old people as not,
[00:30:16.495 - 00:30:23.395] Speaker 2: you know, contributing all that much. And now I've had to change my mind about how, how important old people are.
[00:30:24.335 - 00:30:28.495] Speaker 1: Do you, do you feel difference? I don't, I don't at all.
[00:30:29.210 - 00:30:34.110] Speaker 2: You know, probably if I I took an IQ test, I I would do a little bit worse
[00:30:34.410 - 00:30:36.110] Speaker 2: than when I was 25.
[00:30:37.050 - 00:30:40.190] Speaker 2: But, you know, I've accumulated enough knowledge, you know, so wisdom,
[00:30:41.610 - 00:30:44.990] Speaker 2: you know, can compensate a little bit for a slight,
[00:30:45.555 - 00:30:51.175] Speaker 2: reduction intelligence. And I do think it's like a muscle that if you're pushing yourself to think and learn
[00:30:51.635 - 00:30:53.495] Speaker 2: that, you know, you stay,
[00:30:56.195 - 00:30:57.735] Speaker 2: it really helps your capabilities
[00:30:58.275 - 00:30:58.935] Speaker 2: a lot.
[00:31:00.990 - 00:31:09.650] Speaker 2: But, yeah, I have a fear that, you know, I eventually I'll lose you know, I won't wanna pick up a 500 page book. I'll look at it and go, are you kidding?
[00:31:10.350 - 00:31:11.490] Speaker 2: I'm done with that.
[00:31:12.750 - 00:31:16.130] Speaker 1: So with age, you have not felt any changes in your brain?
[00:31:16.615 - 00:31:17.975] Speaker 1: Not really. In terms of slowing.
[00:31:20.055 - 00:31:21.835] Speaker 2: Wow. No. I don't think so.
[00:31:22.855 - 00:31:26.375] Speaker 2: You know, whenever you can't remember something, you're like, oh, no. Now
[00:31:27.015 - 00:31:27.515] Speaker 2: but,
[00:31:29.480 - 00:31:35.340] Speaker 2: you know, so maybe a tiny bit of that, but then, you know, it's just a little bit because you're you're
[00:31:36.360 - 00:31:42.060] Speaker 2: looking for it. You know, when I was in my twenties, if I can't remember something, I didn't even know. And I was like, so what?
[00:31:43.240 - 00:31:46.265] Speaker 1: So Is there any change you feel? Because
[00:31:46.805 - 00:31:49.465] Speaker 1: so Bill Gates of 25 and Bill Gates of 70,
[00:31:50.085 - 00:31:59.490] Speaker 2: is there any change that you feel personally? Well, in my twenties, I was I chose to focus on one topic from, you know, age 20 to about
[00:32:00.450 - 00:32:01.890] Speaker 2: 31
[00:32:01.890 - 00:32:02.550] Speaker 2: or two.
[00:32:04.450 - 00:32:04.950] Speaker 2: I
[00:32:05.250 - 00:32:07.430] Speaker 2: told myself, hey, I love biology
[00:32:07.730 - 00:32:10.870] Speaker 2: and math and all these things, but I want to be
[00:32:11.410 - 00:32:11.910] Speaker 2: the
[00:32:12.290 - 00:32:13.350] Speaker 2: person who's
[00:32:13.845 - 00:32:15.065] Speaker 2: advancing software
[00:32:15.605 - 00:32:16.105] Speaker 2: faster
[00:32:16.485 - 00:32:18.985] Speaker 2: than anyone else. And so I really did
[00:32:19.525 - 00:32:20.025] Speaker 2: narrow
[00:32:20.405 - 00:32:22.425] Speaker 2: my focus and I I didn't,
[00:32:22.725 - 00:32:23.625] Speaker 2: you know, take
[00:32:24.005 - 00:32:27.330] Speaker 2: much time off. And I could stay in the office, you know,
[00:32:28.290 - 00:32:29.350] Speaker 2: seventy two hours
[00:32:29.730 - 00:32:30.790] Speaker 2: and then crash.
[00:32:32.290 - 00:32:33.750] Speaker 2: And so my adrenaline
[00:32:34.850 - 00:32:35.350] Speaker 2: and
[00:32:35.890 - 00:32:37.030] Speaker 2: was really
[00:32:37.730 - 00:32:38.230] Speaker 2: unique.
[00:32:38.610 - 00:32:40.850] Speaker 2: Now my understanding of how to manage people,
[00:32:42.355 - 00:32:45.735] Speaker 2: other than myself wasn't that, that could, you know, I've,
[00:32:46.115 - 00:32:47.495] Speaker 2: I, I look back and,
[00:32:48.595 - 00:32:51.415] Speaker 2: you know, I've, I've learned a lot since then, but just my
[00:32:51.795 - 00:32:52.295] Speaker 2: stamina,
[00:32:53.795 - 00:32:54.695] Speaker 2: and focus
[00:32:55.080 - 00:32:59.020] Speaker 2: for that period of my life, you know, being kind of a a maniac,
[00:33:00.120 - 00:33:00.620] Speaker 2: was
[00:33:01.000 - 00:33:08.255] Speaker 2: was the right thing. And, you know, I I, you know, my competitors would say, oh, no, you work too hard. And I'd say, yes, I do.
[00:33:09.115 - 00:33:15.775] Speaker 1: Do you think that's a great advice for every young person who's watching? Well A maniac in your twenties. It's not it's not for everyone.
[00:33:17.195 - 00:33:18.255] Speaker 2: But if you're
[00:33:18.635 - 00:33:19.935] Speaker 2: if you're in a race,
[00:33:21.730 - 00:33:22.230] Speaker 2: and,
[00:33:23.890 - 00:33:24.450] Speaker 2: you know, the
[00:33:25.730 - 00:33:28.390] Speaker 2: a little bit moving a little bit faster
[00:33:29.090 - 00:33:30.630] Speaker 2: can make a a difference,
[00:33:31.890 - 00:33:34.870] Speaker 2: then, yes, your your twenties when you have no
[00:33:35.735 - 00:33:37.035] Speaker 2: wife and no children,
[00:33:38.055 - 00:33:39.495] Speaker 2: that's the time to do it.
[00:33:40.295 - 00:33:47.435] Speaker 1: That's the time to be little maniac about certain things. Right? You also just mentioned that you love learning, which
[00:33:47.780 - 00:33:51.320] Speaker 1: obviously, the world knows. But during this conversation also, you just
[00:33:51.780 - 00:33:58.040] Speaker 1: talked about it, like, a little bit again and again. What are you currently learning? Or what do you wanna learn now? Well, there's a lot
[00:33:59.540 - 00:34:00.280] Speaker 2: going on.
[00:34:02.535 - 00:34:06.395] Speaker 2: You know, AI just staying on top of that Mhmm. Is,
[00:34:06.695 - 00:34:07.675] Speaker 2: you know, I
[00:34:08.215 - 00:34:18.590] Speaker 2: I very much enjoy that. And I get to sit and talk with the top people at OpenAI, and I get to play around with things. But then when you think, okay, now about what about AI
[00:34:19.370 - 00:34:21.150] Speaker 2: applied to mental health care?
[00:34:21.930 - 00:34:28.350] Speaker 2: You know, isn't that one of the most exciting things? Because, you know, we can never have enough therapists,
[00:34:29.685 - 00:34:31.145] Speaker 2: and even people who aren't,
[00:34:32.965 - 00:34:34.585] Speaker 2: you know, suffering massively,
[00:34:35.365 - 00:34:37.225] Speaker 2: you know, maybe we could help,
[00:34:38.245 - 00:34:38.745] Speaker 2: even
[00:34:39.765 - 00:34:40.905] Speaker 2: people with mild,
[00:34:41.845 - 00:34:43.865] Speaker 2: symptoms. So, you know, what does this
[00:34:44.390 - 00:34:45.210] Speaker 2: AI companion
[00:34:46.230 - 00:34:48.810] Speaker 2: look like and, you know, how can that
[00:34:50.310 - 00:34:51.130] Speaker 2: help us?
[00:34:51.990 - 00:34:53.210] Speaker 2: My friend Reid Hoffman,
[00:34:53.750 - 00:34:59.050] Speaker 2: just wrote a book called Super Agency that he's got a really good chapter about this. So
[00:34:59.605 - 00:35:02.025] Speaker 2: I'm pushing myself to try and understand,
[00:35:04.165 - 00:35:09.865] Speaker 2: you know, what can we do there and meet the people who are, you know, pushing the the boundaries,
[00:35:10.485 - 00:35:12.265] Speaker 2: because I see such potential.
[00:35:13.000 - 00:35:15.420] Speaker 1: So what would you advise young people
[00:35:15.960 - 00:35:16.780] Speaker 1: to start
[00:35:17.080 - 00:35:18.860] Speaker 1: learning today and from where?
[00:35:19.640 - 00:35:22.220] Speaker 2: AI itself? Well, if you have a mathematical
[00:35:23.080 - 00:35:23.580] Speaker 2: mind,
[00:35:24.200 - 00:35:29.465] Speaker 2: you know, not everyone should learn AI. Okay. You know, these tools are going to be available,
[00:35:30.805 - 00:35:34.025] Speaker 2: to everyone. And so you ought to be a user of AI,
[00:35:34.325 - 00:35:35.385] Speaker 2: but the underlying
[00:35:36.725 - 00:35:40.825] Speaker 2: stuff, you know, that's a pretty narrow set of people who will have an opportunity
[00:35:42.900 - 00:35:45.560] Speaker 2: to, you know, push on a new training method.
[00:35:47.220 - 00:35:49.160] Speaker 2: And even people who grew up with software,
[00:35:49.620 - 00:35:50.520] Speaker 2: some of them
[00:35:50.820 - 00:35:57.755] Speaker 2: don't really get this because it's it's a bit more mathematical than it is just a a programming type thing.
[00:35:59.015 - 00:35:59.515] Speaker 2: So
[00:35:59.815 - 00:36:00.955] Speaker 2: it says a user
[00:36:01.735 - 00:36:05.115] Speaker 2: that, okay, if you're you like doing creative work, yes,
[00:36:06.295 - 00:36:09.595] Speaker 2: AI is gonna change your world and AI hopefully can help you,
[00:36:11.400 - 00:36:12.620] Speaker 2: do things faster
[00:36:13.000 - 00:36:14.540] Speaker 2: and better. So
[00:36:14.840 - 00:36:20.460] Speaker 2: my prescription would be yes to use it for the areas that you're excited about.
[00:36:20.920 - 00:36:28.805] Speaker 1: Any area that excited about, learn from learn about that and try to make a bridge between AI and that industry. Right. I mean,
[00:36:29.505 - 00:36:31.205] Speaker 2: the Internet has so much
[00:36:31.905 - 00:36:35.765] Speaker 2: educational material on it. So between all that material,
[00:36:36.705 - 00:36:43.290] Speaker 2: and then an AI that can help, you know, take long documents and you can have a dialogue with it.
[00:36:44.390 - 00:36:49.910] Speaker 2: You know, you can do it in text or you can, you know, now do these generate podcasts about things. It's,
[00:36:50.550 - 00:36:57.425] Speaker 2: it's a great time to be a learner. Right? You know, when I was young, I had to go to the library and, you know, read the encyclopedia
[00:36:57.805 - 00:36:58.305] Speaker 2: alphabetically.
[00:36:59.165 - 00:36:59.905] Speaker 2: No multimedia.
[00:37:00.445 - 00:37:00.945] Speaker 2: Yeah.
[00:37:01.645 - 00:37:02.545] Speaker 2: This is a
[00:37:03.325 - 00:37:03.825] Speaker 2: paradise.
[00:37:04.525 - 00:37:11.830] Speaker 1: Yeah. Thanks to you guys because The digital world. Yeah. Digital world. You made it easy for us. We don't know the world,
[00:37:12.130 - 00:37:18.230] Speaker 1: what it look like to go to a library and read about something. We get fidgety if we don't get an answer in three seconds.
[00:37:20.210 - 00:37:22.230] Speaker 1: We have lost two questions for you.
[00:37:22.530 - 00:37:25.755] Speaker 1: One is, in your philanthropy work with the foundation,
[00:37:26.535 - 00:37:27.915] Speaker 1: how is India
[00:37:28.455 - 00:37:30.395] Speaker 1: contributing to your global strategies?
[00:37:30.935 - 00:37:31.435] Speaker 2: Well,
[00:37:31.975 - 00:37:33.355] Speaker 2: more and more of the innovation,
[00:37:35.095 - 00:37:36.555] Speaker 2: is being done in India.
[00:37:37.495 - 00:37:37.995] Speaker 2: India's,
[00:37:38.580 - 00:37:39.320] Speaker 2: you know,
[00:37:39.700 - 00:37:41.880] Speaker 2: got a depth of talent and a desire
[00:37:42.660 - 00:37:44.120] Speaker 2: for frugal solutions.
[00:37:44.740 - 00:37:46.520] Speaker 2: And so even though the rich world,
[00:37:47.460 - 00:37:51.800] Speaker 2: US, Europe, you know, we have a lot of talent. And for some basic science thing like immunology,
[00:37:52.755 - 00:37:57.735] Speaker 2: a lot of the new insights will keep coming Yeah. From those institutions.
[00:37:58.195 - 00:37:58.935] Speaker 2: But when
[00:37:59.315 - 00:38:10.380] Speaker 2: it comes to actually putting the pieces together, including something like AI for healthcare, you know, I was just meeting with a number of companies working on on very piece various piece of that in India.
[00:38:11.880 - 00:38:12.380] Speaker 2: And
[00:38:12.840 - 00:38:14.540] Speaker 2: so the, you know, we need
[00:38:15.160 - 00:38:18.380] Speaker 2: better seeds and we need better weather advice for farmers.
[00:38:18.920 - 00:38:19.740] Speaker 2: And so,
[00:38:20.245 - 00:38:25.705] Speaker 2: although we're going to continue to do a lot of implementation here in India, help, you know, get things rolled out,
[00:38:26.965 - 00:38:29.705] Speaker 2: more and more of our sort of product research,
[00:38:30.805 - 00:38:34.265] Speaker 2: work will be done here. Okay. Both because,
[00:38:35.320 - 00:38:36.620] Speaker 2: it benefits India.
[00:38:37.000 - 00:38:39.260] Speaker 2: But, you know, we're also very good if
[00:38:39.720 - 00:38:40.700] Speaker 2: if it's saving
[00:38:41.240 - 00:38:42.940] Speaker 2: Indian children, really working
[00:38:43.480 - 00:38:45.100] Speaker 2: well. You know, our foundation
[00:38:45.800 - 00:38:46.300] Speaker 2: has
[00:38:46.815 - 00:38:47.875] Speaker 2: a lot of presence
[00:38:48.175 - 00:38:59.475] Speaker 2: in Africa. Mhmm. So even take, you know, the classic example where India was totally the leader on this digital public infrastructure, the the digital money and identity adhaar thing,
[00:39:00.380 - 00:39:04.000] Speaker 2: you know, funding the Africans to come here and learn and,
[00:39:04.460 - 00:39:15.365] Speaker 2: for their budgets and create helping to create the open source software that makes it easy for them, you know, that's now a huge agenda item, which is kind of a South South thing with a little bit of facilitation
[00:39:15.665 - 00:39:16.405] Speaker 2: from us.
[00:39:17.345 - 00:39:19.665] Speaker 1: Got it. And here's the last question.
[00:39:22.225 - 00:39:22.725] Speaker 1: If
[00:39:23.825 - 00:39:27.205] Speaker 1: you had if the world had to write one sentence
[00:39:27.910 - 00:39:29.530] Speaker 1: next to the name Bill Gates,
[00:39:30.070 - 00:39:35.530] Speaker 2: what would you want them to write? You know, I don't do my work, you know, based on some epitaph.
[00:39:36.550 - 00:39:37.450] Speaker 2: You know, ideally,
[00:39:38.390 - 00:39:40.970] Speaker 2: you know, they'd say that, wow, there were these diseases
[00:39:42.005 - 00:39:44.425] Speaker 2: around, you know, polio and malaria
[00:39:44.725 - 00:39:45.225] Speaker 2: and,
[00:39:46.005 - 00:39:46.505] Speaker 2: malnutrition.
[00:39:46.965 - 00:39:51.465] Speaker 2: And, you know, now we don't have to think about that, you know, partly because,
[00:39:53.285 - 00:39:54.105] Speaker 2: he championed,
[00:39:54.880 - 00:39:56.580] Speaker 2: you know, putting more,
[00:39:58.560 - 00:40:00.100] Speaker 2: great thinking and resources
[00:40:00.560 - 00:40:04.740] Speaker 2: into ending those problems. And so, you know, I hope people
[00:40:05.280 - 00:40:07.780] Speaker 2: look at the word polio and go, what was that?
[00:40:08.480 - 00:40:09.615] Speaker 2: You know, when you read
[00:40:09.935 - 00:40:18.515] Speaker 2: Dickens' novels and they talk about somebody had consumption, it's like, what is that? Well, that's actually TB. So we still not in The UK, we don't have much, but,
[00:40:18.815 - 00:40:21.075] Speaker 2: we we we still do. They just
[00:40:21.980 - 00:40:24.080] Speaker 2: changed the word. So, you know, hopefully,
[00:40:25.020 - 00:40:27.520] Speaker 2: some problems that that we can actually
[00:40:28.060 - 00:40:28.560] Speaker 2: finish,
[00:40:29.900 - 00:40:34.560] Speaker 1: and and then move on. Which problem do you think we'll be finishing first? Well, polio,
[00:40:36.220 - 00:40:38.675] Speaker 2: you know, I I expect even in five years,
[00:40:39.455 - 00:40:40.755] Speaker 2: and that'll give us,
[00:40:41.375 - 00:40:42.035] Speaker 2: the credibility
[00:40:42.895 - 00:40:45.235] Speaker 2: to go after things like malaria and measles.
[00:40:46.095 - 00:40:48.755] Speaker 2: That's amazing. No. It is. It's gonna be fun.
[00:40:49.055 - 00:40:50.195] Speaker 1: It's it's amazing.
[00:40:50.735 - 00:40:53.270] Speaker 1: In five years, we can make that a reality.
[00:40:53.730 - 00:40:55.670] Speaker 1: It's gonna be incredible for
[00:40:56.050 - 00:41:03.830] Speaker 2: the human kind. It's wow. Yeah. It's only to happen only once. Smallpox was eliminated back in 1980. So, you know, polio,
[00:41:04.210 - 00:41:06.470] Speaker 2: a serious disease, it's gonna be the second.
[00:41:07.545 - 00:41:08.765] Speaker 1: Wow. I
[00:41:09.465 - 00:41:15.805] Speaker 1: really truly wish that it happens faster than what we've just talked about. And I hope, like, more than
[00:41:16.185 - 00:41:17.085] Speaker 1: by the time
[00:41:17.625 - 00:41:33.560] Speaker 1: the foundation gets in full fledged in the work, I I believe instead of not two three that could be month multiple of them so that you you lost counting. That should be the goal and I'm expecting for it. Well, thank you so much for doing this, sir. It was a pleasure having you.
[00:41:34.180 - 00:41:35.320] Speaker 1: When I was
[00:41:35.635 - 00:41:37.655] Speaker 1: a kid, I was growing up in school.
[00:41:39.075 - 00:41:40.455] Speaker 1: Just you were the richest
[00:41:40.835 - 00:41:41.895] Speaker 1: person in the world.
[00:41:42.435 - 00:41:43.815] Speaker 2: Before I gave it away.
[00:41:44.995 - 00:41:54.930] Speaker 1: So your name would pop up. So just to talk about you and how you made your money was a proud feeling in school. And in friend circle, everybody would respect you that, oh, you know so much about
[00:41:55.310 - 00:41:56.690] Speaker 1: this person and that.
[00:41:57.310 - 00:42:06.775] Speaker 1: From there, that kid sitting right in front of you and trying to, you know, being in a situation where I'm sitting with you and figuring out what going on in your brain.
[00:42:07.075 - 00:42:09.975] Speaker 1: It's an incredible opportunity. I'm so grateful.
[00:42:10.355 - 00:42:17.975] Speaker 1: Thank you so much for doing this. It's a dream come true. Great. We'll have to do it again. Yes. We need to. I've got you on camera now.
[00:42:18.275 - 00:42:20.230] Speaker 1: Thank you. Thank you. Pleasure.
[00:42:20.690 - 00:42:23.830] Speaker 1: I'm definitely a little nervous because it's a big, big, big, big vodka.
[00:42:26.930 - 00:42:31.270] Speaker 1: It's time. It's time. It's time. It's time. Good job. I'm excited.
[00:42:32.850 - 00:42:33.910] Speaker 1: Hi. Hi,
[00:42:34.865 - 00:42:39.285] Speaker 1: How are you? Very good. How are you? Pleasure meeting you, Sophie. How are you? Yes.
[00:42:39.585 - 00:42:42.725] Speaker 1: That's fine. It's it's a pleasure seeing you here, though.
[00:42:43.105 - 00:42:45.365] Speaker 1: I'm pretty nervous at this point. Uh-oh.
[00:42:45.825 - 00:42:49.525] Speaker 1: Just bear with me. I'm pretty busy. Good. Good. I had
[00:42:49.910 - 00:42:50.870] Speaker 1: 500,000
[00:42:50.870 - 00:42:52.730] Speaker 1: things to talk to you and now I'm speechless.
[00:42:53.110 - 00:42:54.390] Speaker 1: I like there's nothing in my
[00:42:55.830 - 00:43:00.810] Speaker 1: Thank you so much for watching this episode till the end. Please let us know in the comments
[00:43:01.190 - 00:43:03.770] Speaker 1: who are the next guest that you wanna see
[00:43:04.425 - 00:43:05.485] Speaker 1: on this show
[00:43:06.025 - 00:43:06.525] Speaker 1: because
[00:43:07.065 - 00:43:13.245] Speaker 1: we are determined to get the best of the best minds from the world and provide you the maximum value.
[00:43:13.785 - 00:43:19.325] Speaker 1: I'll see you next time. Until then, keep figuring out and don't forget to share this episode with at least one person
[00:43:20.160 - 00:43:21.140] Speaker 1: just keep life positive
[00:43:21.520 - 00:43:22.020] Speaker 1: change.
